*blink-ai.txt*  AI completions for blink.cmp

==============================================================================
INTRO                                                                    *blink-ai*

blink-ai.nvim injects AI completions into the blink.cmp completion menu.

Requirements:
- Neovim 0.10+
- curl
- saghen/blink.cmp

Compatibility:
- Neovim 0.10+ (CI tested on stable and v0.10.4)
- Providers: OpenAI, Anthropic, Ollama, OpenAI-compatible, FIM
- Global provider env vars are ignored by default; use BLINK_* vars.

==============================================================================
SETUP                                                             *blink-ai-setup*

Use your plugin manager to load blink-ai.nvim, then call:

  lua require("blink-ai").setup({ ... })

Example source wiring for blink.cmp:

  sources = {
    default = { "lsp", "path", "snippets", "buffer", "ai" },
    providers = {
      ai = {
        name = "AI",
        module = "blink-ai",
        async = true,
        timeout_ms = 5000,
        score_offset = 10,
      },
    },
  }

==============================================================================
CONFIG                                                          *blink-ai-config*

provider                    Active provider name.
performance_profile         Runtime profile: fast, balanced, or quality.
provider_overrides          Per-filetype provider/model overrides.
debounce_ms                 Debounce delay before requests.
max_tokens                  Max tokens requested per completion.
n_completions               Number of completion candidates.
suggestion_mode             "raw" (default) or "paired" output shaping.
context.before_cursor_lines Lines before cursor to include.
context.after_cursor_lines  Lines after cursor to include.
context.enable_treesitter   Include syntax node metadata when available.
context.user_context        fun(ctx) -> string|nil extra context hook.
context.repo.*              Import-aware project snippet context.
stats.enabled               Track local request metrics for status command.
filetypes                   Allowlist of filetypes (empty = all).
filetypes_exclude           Blocklist of filetypes.
notify_on_error             Notify via vim.notify on errors.
providers                   Provider-specific configuration.
system_prompt               String or function(ctx) -> string override.
transform_items             fun(items) -> items hook.

Suggestion modes:
- raw: return provider candidates unchanged.
- paired: at most two items (single-line + full-form/multiline).
- During request execution, one AI (thinking...) placeholder item is shown.
- Streamed provider chunks are buffered internally and the menu updates with
  the final AI result.
- AI items use a bot icon (ó°š©) in blink.cmp.

Note: timeout_ms is configured in blink.cmp under
sources.providers.ai.timeout_ms.

==============================================================================
PROVIDERS                                                     *blink-ai-providers*

openai
  Responses API over SSE.
  Defaults to BLINK_OPENAI_API_KEY.
  Supports fast_model + model_strategy for typing-time routing.

anthropic
  Messages API over SSE.
  Defaults to BLINK_ANTHROPIC_API_KEY.

ollama
  Supports /v1/chat/completions, /api/chat, and /api/generate.
  No auth required by default.

openai_compatible
  Generic OpenAI-style chat endpoint.
  Defaults to BLINK_OPENAI_COMPATIBLE_API_KEY.

fim
  Generic fill-in-the-middle endpoint.
  Uses configurable fim_tokens and defaults to BLINK_FIM_API_KEY.

==============================================================================
COMMANDS                                                     *blink-ai-commands*

:BlinkAI status              Show provider, configured/effective model, and request status.
:BlinkAI toggle              Enable/disable the source globally.
:BlinkAI provider {name}     Switch the active provider.
:BlinkAI model {name}        Switch the model for the active provider.
:BlinkAI clear               Cancel any in-flight request.
:BlinkAI stats status        Show metrics.
:BlinkAI stats reset         Reset metrics and last error.

==============================================================================
QUALITY                                                       *blink-ai-quality*

Local release-quality commands:
- make format-check
- make lint
- make docs-check
- make test
- make test-all

Release metadata files:
- CHANGELOG.md
- CONTRIBUTING.md
- SECURITY.md
- RELEASE_CHECKLIST.md

==============================================================================
TROUBLESHOOTING                                           *blink-ai-troubleshoot*

- Missing keys notify once. Set provider-specific env vars or config values.
- Ensure curl is available and Neovim is 0.10+.
- Run :checkhealth blink-ai for environment/provider diagnostics.
- Check :BlinkAI status for active provider, model, and last error.
- Verify your blink.cmp source uses module = "blink-ai".
- Increase debounce_ms if requests fire too often.
- Increase sources.providers.ai.timeout_ms if requests time out.
- For OpenAI models like gpt-5.2-codex, unset providers.openai.temperature unless
  the model explicitly supports it.
- For OpenAI models returning 404, verify provider is openai and endpoint is
  /v1/responses.
- OpenAI-compatible/FIM endpoints may require custom extra_body fields.

==============================================================================
LICENSE                                                         *blink-ai-license*

MIT
